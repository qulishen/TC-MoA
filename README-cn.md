# ç®€ä»‹ ğŸŒŸ
è¿™æ˜¯è®ºæ–‡ **Task-Customized Mixture of Adapters for General Image Fusion** çš„éå®˜æ–¹ä»£ç ï¼Œè§£å†³äº†æ¨ç†å›¾ç‰‡ä¸ºé»‘è‰²çš„é—®é¢˜ã€‚[é—®é¢˜é“¾æ¥](https://github.com/YangSun22/TC-MoA/issues/2)

[English Version (è‹±æ–‡ç‰ˆæœ¬)](README.md)

# å‡†å¤‡ ğŸ› ï¸

## é¢„è®­ç»ƒæ¨¡å‹ï¼š
æ¥è‡ª MAE ([GitHub - facebookresearch/mae: PyTorch implementation of MAE](https://github.com/facebookresearch/mae))

```bash
!wget -nc https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_large_ganloss.pth
!wget -nc https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_base.pth
```

## æ•°æ®é›†ï¼š
- **ç™¾åº¦äº‘**: [é“¾æ¥](https://pan.baidu.com/s/1R2R58PjJuMaS2P4uwlTBqg?pwd=hyqv) æå–ç : `hyqv`
- **Google Drive**: [é“¾æ¥](https://drive.google.com/drive/folders/1yFHwmebySDmgLwImQRT-XdEVZ6HjO1Vc?usp=drive_link)

## TC-MoA æ¨¡å‹ï¼š
- **ç™¾åº¦äº‘**: [é“¾æ¥](https://pan.baidu.com/s/19u8OgMQbQqfvNyaDkmRlNQ?pwd=iqzf) æå–ç : `iqzf`
- **Google Drive**: [é“¾æ¥](https://drive.google.com/file/d/1S23P6Sw-UQMaPY16XxOnegojjEexm3ER/view?usp=drive_link)

# è®­ç»ƒ ğŸš€

```bash
CUDA_VISIBLE_DEVICES=0,1,2 CUDA_LAUNCH_BLOCKING=1 NCCL_P2P_LEVEL=NVL nohup python -m torch.distributed.launch \
    --nproc_per_node 3 --master_port 22222 \
    main_train.py --config_path ./config/base.yaml \
     > test.log 2>&1 & 
```

# æµ‹è¯• ğŸ§ª

```bash
CUDA_VISIBLE_DEVICES=0 python main_predict.py --config_path ./config/predict.yaml
```

æµ‹è¯•æ•°æ®é›†çš„æ–‡ä»¶å¤¹è·¯å¾„æ ¼å¼å¦‚ä¸‹ï¼š

```python
for dataset_name in self.EvalDataSet.keys():
    ddir = self.EvalDataSet[dataset_name]

    if dataset_name in ["LLVIP", "LLVIP_Test"]:       
        rgb_dir = os.path.join(ddir, "visible", "test")     # RGB
        t_dir = os.path.join(ddir, "infrared", "test")      # çº¢å¤–
    elif dataset_name in ["MandP", "M3FD"]:
        rgb_dir = os.path.join(ddir, "vi")     # RGB
        t_dir = os.path.join(ddir, "ir")      # çº¢å¤–
    elif dataset_name in ["MEFB", "MEF", "MFF"]:
        rgb_dir = os.path.join(ddir, "input")             # è¿‡æ›
        t_dir = os.path.join(ddir, "input")               # ä½æ›
    elif dataset_name == "Lytro":
        rgb_dir = os.path.join(ddir, "BB")     # è¿œç„¦
        t_dir = os.path.join(ddir, "AA")       # è¿‘ç„¦
    elif dataset_name == "TNO":
        rgb_dir = os.path.join(ddir, "vi")     # RGB
        t_dir = os.path.join(ddir, "ir")      # çº¢å¤–
    elif dataset_name == "SCIE_test":
        rgb_dir = os.path.join(ddir, "oe")     # RGB
        t_dir = os.path.join(ddir, "ue")
    else:
        print("æ•°æ®é›†åç§°é”™è¯¯ï¼", dataset_name)
```

# å¼•ç”¨ ğŸ“œ

å¦‚æœæ‚¨ä½¿ç”¨äº†æ­¤ä»£ç ï¼Œè¯·å¼•ç”¨ï¼š

```
@InProceedings{Zhu_2024_CVPR,
    author    = {Zhu, Pengfei and Sun, Yang and Cao, Bing and Hu, Qinghua},
    title     = {Task-Customized Mixture of Adapters for General Image Fusion},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2024},
    pages     = {7099-7108}
}
```

---
